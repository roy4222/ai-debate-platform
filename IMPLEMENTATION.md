# DebateAI å°ˆæ¡ˆå¯¦æ–½æŒ‡å—

> **æœ¬æ–‡ä»¶åŒ…å«å®Œæ•´çš„æŠ€è¡“å¯¦æ–½ç´°ç¯€ã€ç¨‹å¼ç¢¼ç¯„ä¾‹å’Œéƒ¨ç½²æŒ‡å—**

## ç›®éŒ„

- [å°ˆæ¡ˆç¾ç‹€](#å°ˆæ¡ˆç¾ç‹€)
- [å¯è¡Œæ€§è©•ä¼°](#å¯è¡Œæ€§è©•ä¼°)
- [é—œéµæŠ€è¡“æ±ºç­–](#é—œéµæŠ€è¡“æ±ºç­–)
- [é–‹ç™¼æ™‚ç¨‹](#é–‹ç™¼æ™‚ç¨‹)
- [Phase 0: å°ˆæ¡ˆåˆå§‹åŒ–](#phase-0-å°ˆæ¡ˆåˆå§‹åŒ–)
- [Phase 1: åŸºç¤æ¶æ§‹é€£é€š](#phase-1-åŸºç¤æ¶æ§‹é€£é€š)
- [Phase 2: æ¥å…¥ LangGraph èˆ‡ Groq](#phase-2-æ¥å…¥-langgraph-èˆ‡-groq)
- [Phase 3: å·¥å…·èª¿ç”¨èˆ‡å®Œå–„](#phase-3-å·¥å…·èª¿ç”¨èˆ‡å®Œå–„)
- [é—œéµæŠ€è¡“è¦é»](#é—œéµæŠ€è¡“è¦é»)
- [é¢¨éšªç·©è§£ç­–ç•¥](#é¢¨éšªç·©è§£ç­–ç•¥)

---

## å°ˆæ¡ˆç¾ç‹€

- **ç‹€æ…‹**: è¨­è¨ˆå®Œæˆï¼Œå¯¦ç¾æœªé–‹å§‹
- **å·²æœ‰**: å®Œæ•´çš„æŠ€è¡“è¦æ ¼æ›¸ï¼ˆREADME.mdï¼‰
- **ç¼ºå¤±**: æ‰€æœ‰å‰å¾Œç«¯ä»£ç¢¼ã€é…ç½®æ–‡ä»¶ã€éƒ¨ç½²è¨­å®š

---

## å¯è¡Œæ€§è©•ä¼°

### âœ… å„ªå‹¢ï¼ˆé«˜å¯è¡Œæ€§å› ç´ ï¼‰

1. **å®Œæ•´çš„æŠ€è¡“è¦åŠƒ**
   - æ¸…æ™°çš„ä¸‰éšæ®µé–‹ç™¼è·¯ç·šåœ–
   - è©³ç´°çš„æŠ€è¡“å †ç–Šé¸å‹
   - æ˜ç¢ºçš„éƒ¨ç½²ç­–ç•¥

2. **æˆç†Ÿçš„æŠ€è¡“é¸å‹**
   - **Python LangGraph 0.2+**: æœ€æ–°ç‰ˆæœ¬çš„ multi-agent æ¡†æ¶
   - **FastAPI**: é«˜æ•ˆèƒ½çš„ Python web æ¡†æ¶ï¼ŒåŸç”Ÿæ”¯æ´ async/SSE
   - **Next.js 14+**: ç©©å®šçš„ React æ¡†æ¶
   - **Groq**: æ¥­ç•Œé ˜å…ˆçš„æ¨ç†é€Ÿåº¦ï¼ˆ300+ tokens/secï¼‰
   - **uv**: ç¾ä»£åŒ–çš„ Python å·¥å…·éˆ

3. **æˆæœ¬å„ªåŒ–**
   - Google Cloud Run: æ…·æ…¨çš„å…è²»é¡åº¦ï¼ˆæ¯æœˆ 200 è¬æ¬¡è«‹æ±‚ï¼‰
   - Cloudflare Pages: å®Œå…¨å…è²»çš„éœæ…‹è¨—ç®¡
   - Tavily: 1000 æ¬¡/æœˆå…è²»æœå°‹
   - Groq: æ¯æ—¥æœ‰å…è²»é¡åº¦

4. **æ¶æ§‹åˆç†æ€§**
   - å‰å¾Œç«¯åˆ†é›¢ï¼Œè·è²¬æ¸…æ™°
   - SSE é©åˆ AI ä¸²æµå ´æ™¯
   - Docker å®¹å™¨åŒ–æ˜“æ–¼éƒ¨ç½²

### ğŸ“Š å¯è¡Œæ€§çµè«–

**ç¸½é«”è©•åˆ†: 9/10 (é«˜åº¦å¯è¡Œ)**

- âœ… æŠ€è¡“é¸å‹åˆç†ä¸”æˆç†Ÿ
- âœ… æ¶æ§‹è¨­è¨ˆæ¸…æ™°å¯åŸ·è¡Œ
- âœ… æˆæœ¬å¯æ§ï¼ˆæ¥è¿‘é›¶æˆæœ¬ï¼‰
- âœ… ä½¿ç”¨ç¾ä»£åŒ–å·¥å…·éˆï¼ˆuvï¼‰
- âš ï¸ éœ€è¦ä¸­ç­‰ç¨‹åº¦çš„å…¨ç«¯é–‹ç™¼èƒ½åŠ›

---

## é—œéµæŠ€è¡“æ±ºç­–

### 1. ä½¿ç”¨ uv å…¨å®¶æ¡¶

**ç‚ºä»€éº¼é¸æ“‡ uvï¼Ÿ**
- æ¯” pip å¿« 10-100 å€
- å…§å»ºä¾è³´é–å®šï¼ˆuv.lockï¼‰
- çµ±ä¸€çš„å·¥å…·éˆï¼ˆå–ä»£ pipã€pip-toolsã€virtualenvï¼‰
- å®˜æ–¹ Docker æ˜ åƒæ”¯æ´

**å®‰è£ uv:**
```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# æˆ–ä½¿ç”¨ pip
pip install uv
```

### 2. æœå°‹å·¥å…·ç­–ç•¥ï¼šTavily å„ªå…ˆ + DuckDuckGo å‚™æ´

**å•é¡Œï¼š** DuckDuckGo ä¸ç©©å®šï¼ˆåŸºæ–¼çˆ¬èŸ²ï¼Œå¸¸è¢«æ“‹ IPï¼‰

**è§£æ±ºæ–¹æ¡ˆï¼š** ä¸‰å±¤å®¹éŒ¯æ©Ÿåˆ¶
1. **ä¸»è¦ç­–ç•¥**: ä½¿ç”¨ Tavilyï¼ˆå°ˆç‚º AI è¨­è¨ˆï¼Œæ¥µåº¦ç©©å®šï¼‰
2. **å‚™æ´ç­–ç•¥**: Tavily å¤±æ•—æ™‚è‡ªå‹•åˆ‡æ›åˆ° DuckDuckGo
3. **å„ªé›…é™ç´š**: å…©è€…éƒ½å¤±æ•—æ™‚ï¼ŒåŸºæ–¼å·²çŸ¥çŸ¥è­˜å›ç­”ï¼ˆä¸æœƒå´©æ½°ï¼‰

**å¥½è™•ï¼š**
- Demo æ°¸é ä¸æœƒåœ¨é¢è©¦å®˜é¢å‰å´©æ½°
- Tavily 1000 æ¬¡/æœˆå…è²»é¡åº¦è¶³å¤ å±•ç¤º
- DuckDuckGo ä½œç‚ºç„¡é™æ¬¡æ•¸å‚™æ´

### 3. Cloud Run å†·å•Ÿå‹•å„ªåŒ–

**å•é¡Œï¼š** æœ€å°å¯¦ä¾‹è¨­ç‚º 0 æœƒå°è‡´ 15 åˆ†é˜å¾Œå†·å•Ÿå‹•ï¼ˆ10-15 ç§’å»¶é²ï¼‰

**è§£æ±ºæ–¹æ¡ˆï¼š**

#### æ–¹æ¡ˆ A: å‰ç«¯ UX å„ªåŒ–ï¼ˆé›¶æˆæœ¬ï¼Œå¿…åšï¼‰
åœ¨å‰ç«¯é¡¯ç¤ºã€Œæ­£åœ¨å–šé†’ AI å¼•æ“...ã€æç¤ºï¼Œè®“ä½¿ç”¨è€…æœ‰å¿ƒç†æº–å‚™

#### æ–¹æ¡ˆ B: Keep-Alive è…³æœ¬ï¼ˆDemo ç•¶å¤©ä½¿ç”¨ï¼‰
Demo å‰ 30 åˆ†é˜åŸ·è¡Œè…³æœ¬ï¼Œæ¯ 5 åˆ†é˜ ping ä¸€æ¬¡ä¿æŒæº«ç†±

#### æ–¹æ¡ˆ C: æœ€å°å¯¦ä¾‹ = 1ï¼ˆç´„ $5-10/æœˆï¼‰
åƒ…åœ¨é‡è¦å±•ç¤ºæœŸé–“å•Ÿç”¨

---

## é–‹ç™¼æ™‚ç¨‹

### Week 1: åŸºç¤å»ºè¨­ + å­¸ç¿’æœŸ
- **Day 1-2**: Phase 0 - å°ˆæ¡ˆçµæ§‹å»ºç«‹ã€ç’°å¢ƒé…ç½®ã€GCP/Cloudflare å¸³è™Ÿè¨­å®š
- **Day 3-4**: Phase 1 - å¯¦ç¾åŸºç¤ SSE ä¸²æµï¼ˆæœ¬åœ° + é›²ç«¯éƒ¨ç½²ï¼‰
- **Day 5-7**: å­¸ç¿’ LangGraphï¼Œé–±è®€æ–‡æª”ï¼Œå˜—è©¦ç°¡å–®ç¯„ä¾‹

### Week 2: æ ¸å¿ƒåŠŸèƒ½é–‹ç™¼
- **Day 8-10**: Phase 2 - å¯¦ç¾é›™ Agent è¾¯è«–ï¼ˆOptimist + Skepticï¼‰
- **Day 11-12**: å„ªåŒ–ä¸²æµé«”é©—ï¼Œè™•ç†éŒ¯èª¤æƒ…æ³
- **Day 13-14**: å‰ç«¯ UI ç¾åŒ–ï¼ŒåŠ å…¥å‹•ç•«æ•ˆæœ

### Week 3: é€²éšåŠŸèƒ½
- **Day 15-17**: Phase 3 - æ•´åˆæœå°‹å·¥å…·ï¼ˆTavily + DuckDuckGoï¼‰
- **Day 18-19**: å¯¦ç¾ Moderator ç¸½çµåŠŸèƒ½
- **Day 20-21**: æ¸¬è©¦èˆ‡ bug ä¿®å¾©

### Week 4: å®Œå–„èˆ‡æ“´å±•
- **Day 22-24**: è¿½åŠ åŠŸèƒ½ï¼ˆä¸»é¡Œæ¨¡æ¿ã€å°è©±æ­·å²ç­‰ï¼‰
- **Day 25-27**: æ–‡æª”æ’°å¯«ã€éƒ¨ç½²å„ªåŒ–
- **Day 28-30**: æœ€çµ‚æ¸¬è©¦ã€æº–å‚™å±•ç¤ºææ–™

---

## Phase 0: å°ˆæ¡ˆåˆå§‹åŒ–

### ç›®æ¨™
å»ºç«‹å®Œæ•´çš„å°ˆæ¡ˆéª¨æ¶ï¼Œé…ç½®æ‰€æœ‰å¿…è¦çš„ç’°å¢ƒ

### å¾Œç«¯è¨­ç½®

#### 1. å»ºç«‹ç›®éŒ„çµæ§‹
```bash
mkdir -p backend/app/{agents,tools}
cd backend
```

#### 2. å‰µå»º `pyproject.toml`
```toml
[project]
name = "debate-ai-backend"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.30.0",
    "langchain>=0.3.0",
    "langchain-groq>=0.2.0",
    "langgraph>=0.2.0",
    "tavily-python>=0.5.0",
    "duckduckgo-search>=6.0.0",
    "python-dotenv>=1.0.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

#### 3. å®‰è£ä¾è³´
```bash
# ä½¿ç”¨ uv å®‰è£ä¾è³´
uv sync

# æˆ–ä½¿ç”¨ uv pip
uv pip install -e .
```

#### 4. å‰µå»º `.env.example`
```bash
GROQ_API_KEY=your_groq_key_here
TAVILY_API_KEY=your_tavily_key_here
ENVIRONMENT=development
```

#### 5. å‰µå»º `Dockerfile`
```dockerfile
FROM ghcr.io/astral-sh/uv:python3.11-bookworm-slim

WORKDIR /app

# è¤‡è£½å°ˆæ¡ˆæª”æ¡ˆ
COPY pyproject.toml .
COPY uv.lock* .

# å®‰è£ä¾è³´
RUN uv sync --frozen --no-dev

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ç¢¼
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8080

# å•Ÿå‹•æ‡‰ç”¨
CMD ["uv", "run", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
```

#### 6. å‰µå»º `app/main.py` éª¨æ¶
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="DebateAI API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "https://*.pages.dev"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
async def health():
    return {"status": "ok", "message": "DebateAI API is running"}
```

#### 7. æ¸¬è©¦å¾Œç«¯
```bash
# ä½¿ç”¨ uv é‹è¡Œ
uv run uvicorn app.main:app --reload --port 8000

# æ¸¬è©¦ health endpoint
curl http://localhost:8000/health
```

### å‰ç«¯è¨­ç½®

#### 1. å»ºç«‹ Next.js å°ˆæ¡ˆ
```bash
npx create-next-app@latest frontend --typescript --tailwind --app --no-src-dir
cd frontend
```

#### 2. å‰µå»º `.env.local.example`
```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

#### 3. é…ç½® `next.config.js`
```javascript
/** @type {import('next').NextConfig} */
const nextConfig = {
  output: 'export',  // éœæ…‹å°å‡ºï¼Œé©åˆ Cloudflare Pages
}

module.exports = nextConfig
```

#### 4. æ¸¬è©¦å‰ç«¯
```bash
npm run dev
# è¨ªå• http://localhost:3000
```

### éƒ¨ç½²æº–å‚™

#### 1. Google Cloud Platform
```bash
# å®‰è£ gcloud CLI
# https://cloud.google.com/sdk/docs/install

# åˆå§‹åŒ–
gcloud init

# å»ºç«‹å°ˆæ¡ˆ
gcloud projects create debate-ai-demo --name="DebateAI"

# è¨­å®šå°ˆæ¡ˆ
gcloud config set project debate-ai-demo

# å•Ÿç”¨ Cloud Run API
gcloud services enable run.googleapis.com
```

#### 2. Cloudflare å¸³è™Ÿ
- è¨»å†Š Cloudflare å¸³è™Ÿï¼šhttps://dash.cloudflare.com/sign-up
- å®‰è£ Wrangler CLIï¼š`npm install -g wrangler`

#### 3. API Keys
- **Groq**: https://console.groq.com/keys
- **Tavily**: https://app.tavily.com/

---

## Phase 1: åŸºç¤æ¶æ§‹é€£é€š

### ç›®æ¨™
å¯¦ç¾æœ€ç°¡å–®çš„ SSE ä¸²æµï¼Œç¢ºèªå‰å¾Œç«¯é€šè¨Šæ­£å¸¸

### å¾Œç«¯å¯¦ä½œ

æ›´æ–° `backend/app/main.py`:

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
import asyncio

app = FastAPI(title="DebateAI API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "https://*.pages.dev"],
    allow_methods=["*"],
    allow_headers=["*"],
)

async def fake_stream():
    """Phase 1 æ¸¬è©¦ï¼šæ¯ç§’ç™¼é€ä¸€å€‹å­—"""
    words = ["Hello", " ", "World", "!", " ", "SSE", " ", "is", " ", "working!"]
    for word in words:
        yield f"data: {word}\n\n"
        await asyncio.sleep(0.5)

@app.get("/stream")
async def stream_endpoint():
    return StreamingResponse(fake_stream(), media_type="text/event-stream")

@app.get("/health")
async def health():
    return {"status": "ok"}
```

### å‰ç«¯å¯¦ä½œ

å‰µå»º `frontend/app/page.tsx`:

```typescript
'use client';

import { useState } from 'react';

export default function Home() {
  const [message, setMessage] = useState('');
  const [isConnected, setIsConnected] = useState(false);

  const startStream = () => {
    const eventSource = new EventSource(
      process.env.NEXT_PUBLIC_API_URL + '/stream'
    );

    eventSource.onopen = () => setIsConnected(true);
    eventSource.onmessage = (event) => {
      setMessage((prev) => prev + event.data);
    };
    eventSource.onerror = () => {
      setIsConnected(false);
      eventSource.close();
    };
  };

  return (
    <div className="min-h-screen p-8 bg-gray-50">
      <h1 className="text-2xl mb-4 font-bold">DebateAI - Phase 1 Test</h1>
      <button
        onClick={startStream}
        className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600"
      >
        Start Stream
      </button>
      <div className="mt-4 p-4 border rounded bg-white">
        {isConnected && <span className="text-green-500">â— Connected</span>}
        <p className="mt-2 font-mono">{message}</p>
      </div>
    </div>
  );
}
```

### æœ¬åœ°æ¸¬è©¦

```bash
# çµ‚ç«¯ 1: å•Ÿå‹•å¾Œç«¯
cd backend
uv run uvicorn app.main:app --reload --port 8000

# çµ‚ç«¯ 2: å•Ÿå‹•å‰ç«¯
cd frontend
npm run dev
```

è¨ªå• http://localhost:3000ï¼Œé»æ“Š "Start Stream"ï¼Œæ‡‰è©²çœ‹åˆ° "Hello World! SSE is working!" é€å­—é¡¯ç¤ºã€‚

### éƒ¨ç½²åˆ°é›²ç«¯

#### éƒ¨ç½²å¾Œç«¯åˆ° Cloud Run

```bash
cd backend

# éƒ¨ç½²
gcloud run deploy debate-api \
  --source . \
  --region asia-east1 \
  --allow-unauthenticated \
  --set-env-vars ENVIRONMENT=production \
  --memory 512Mi \
  --cpu 1 \
  --timeout 300 \
  --min-instances 0 \
  --max-instances 10

# è¨˜ä¸‹è¼¸å‡ºçš„ URLï¼Œä¾‹å¦‚ï¼š
# https://debate-api-xxxxx-as.a.run.app
```

#### éƒ¨ç½²å‰ç«¯åˆ° Cloudflare Pages

```bash
cd frontend

# æ›´æ–° .env.local
NEXT_PUBLIC_API_URL=https://debate-api-xxxxx-as.a.run.app

# æ§‹å»º
npm run build

# éƒ¨ç½²ï¼ˆé¦–æ¬¡æœƒè¦æ±‚ç™»å…¥ï¼‰
npx wrangler pages deploy out --project-name debate-ai
```

### é©—æ”¶æ¨™æº–

- âœ… ç€è¦½å™¨å¯ä»¥çœ‹åˆ° "Hello World! SSE is working!" é€å­—é¡¯ç¤º
- âœ… æœ¬åœ°å’Œé›²ç«¯éƒ½èƒ½æ­£å¸¸é‹è¡Œ
- âœ… ç„¡ CORS éŒ¯èª¤

---

## Phase 2: æ¥å…¥ LangGraph èˆ‡ Groq

### ç›®æ¨™
å¯¦ç¾çœŸæ­£çš„ AI è¾¯è«–

### å¾Œç«¯å¯¦ä½œ

#### 1. å‰µå»º `backend/app/graph.py`

```python
from typing import TypedDict, Literal, List
from langchain_core.messages import BaseMessage, AIMessage
from langchain_groq import ChatGroq
from langgraph.graph import StateGraph, END
import os

class DebateState(TypedDict):
    """è¾¯è«–ç‹€æ…‹"""
    messages: List[BaseMessage]
    topic: str
    current_speaker: Literal["optimist", "skeptic", "end"]
    round_count: int
    max_rounds: int

# åˆå§‹åŒ– Groq LLM
llm = ChatGroq(
    model="llama-3.1-70b-versatile",
    temperature=0.7,
    api_key=os.getenv("GROQ_API_KEY"),
    streaming=True
)

def optimist_node(state: DebateState) -> dict:
    """æ¨‚è§€è€… Agent"""
    prompt = f"""ä½ æ˜¯ä¸€ä½æ¨‚è§€çš„è¾¯æ‰‹ã€‚ä¸»é¡Œï¼š{state['topic']}

è«‹å¾ç©æ¥µçš„è§’åº¦è«–è¿°ï¼Œå¼·èª¿å„ªé»ã€æ©Ÿæœƒå’Œå¯èƒ½æ€§ã€‚ä¿æŒç°¡æ½”ï¼ˆ2-3 å¥è©±ï¼‰ã€‚

ä¹‹å‰çš„å°è©±ï¼š
{format_messages(state['messages'][-4:])}"""

    response = llm.invoke(prompt)

    return {
        "messages": state["messages"] + [AIMessage(content=response.content, name="optimist")],
        "current_speaker": "skeptic",
        "round_count": state["round_count"]
    }

def skeptic_node(state: DebateState) -> dict:
    """æ‡·ç–‘è€… Agent"""
    prompt = f"""ä½ æ˜¯ä¸€ä½ç†æ€§çš„æ‡·ç–‘è€…ã€‚ä¸»é¡Œï¼š{state['topic']}

è«‹å¾æ‰¹åˆ¤çš„è§’åº¦è«–è¿°ï¼ŒæŒ‡å‡ºé¢¨éšªã€å•é¡Œå’ŒæŒ‘æˆ°ã€‚ä¿æŒç°¡æ½”ï¼ˆ2-3 å¥è©±ï¼‰ã€‚

ä¹‹å‰çš„å°è©±ï¼š
{format_messages(state['messages'][-4:])}"""

    response = llm.invoke(prompt)

    new_round = state["round_count"] + 1
    next_speaker = "end" if new_round >= state["max_rounds"] else "optimist"

    return {
        "messages": state["messages"] + [AIMessage(content=response.content, name="skeptic")],
        "current_speaker": next_speaker,
        "round_count": new_round
    }

def format_messages(messages: List[BaseMessage]) -> str:
    """æ ¼å¼åŒ–è¨Šæ¯æ­·å²"""
    return "\n".join([
        f"{m.name}: {m.content}"
        for m in messages
        if hasattr(m, 'name')
    ])

def should_continue(state: DebateState) -> str:
    """æ±ºå®šä¸‹ä¸€å€‹ç¯€é»"""
    return state["current_speaker"]

# å»ºç«‹ StateGraph
graph = StateGraph(DebateState)
graph.add_node("optimist", optimist_node)
graph.add_node("skeptic", skeptic_node)

# è¨­å®šå…¥å£é»
graph.set_conditional_entry_point(
    should_continue,
    {
        "optimist": "optimist",
        "skeptic": "skeptic",
        "end": END
    }
)

# è¨­å®šé‚Š
graph.add_conditional_edges(
    "optimist",
    should_continue,
    {
        "skeptic": "skeptic",
        "end": END
    }
)

graph.add_conditional_edges(
    "skeptic",
    should_continue,
    {
        "optimist": "optimist",
        "end": END
    }
)

# ç·¨è­¯
debate_graph = graph.compile()
```

#### 2. æ›´æ–° `backend/app/main.py`

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from app.graph import debate_graph, DebateState
import json
import os
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(title="DebateAI API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "https://*.pages.dev"],
    allow_methods=["*"],
    allow_headers=["*"],
)

class DebateRequest(BaseModel):
    topic: str
    max_rounds: int = 3

async def debate_stream(topic: str, max_rounds: int):
    """ä¸²æµ AI è¾¯è«–"""
    initial_state: DebateState = {
        "messages": [],
        "topic": topic,
        "current_speaker": "optimist",
        "round_count": 0,
        "max_rounds": max_rounds
    }

    async for event in debate_graph.astream_events(initial_state, version="v1"):
        # ç›£è½ LLM token ä¸²æµ
        if event["event"] == "on_chat_model_stream":
            chunk = event["data"]["chunk"]
            if hasattr(chunk, 'content') and chunk.content:
                node = event["metadata"].get("langgraph_node", "unknown")
                data = {
                    "node": node,
                    "text": chunk.content,
                    "type": "token"
                }
                yield f"data: {json.dumps(data)}\n\n"

        # ç›£è½ç¯€é»çµæŸ
        elif event["event"] == "on_chain_end" and "langgraph_node" in event["metadata"]:
            node = event["metadata"]["langgraph_node"]
            data = {
                "node": node,
                "type": "node_end"
            }
            yield f"data: {json.dumps(data)}\n\n"

@app.post("/debate")
async def start_debate(request: DebateRequest):
    """é–‹å§‹è¾¯è«–"""
    return StreamingResponse(
        debate_stream(request.topic, request.max_rounds),
        media_type="text/event-stream"
    )

@app.get("/health")
async def health():
    return {"status": "ok"}
```

### å‰ç«¯å¯¦ä½œ

æ›´æ–° `frontend/app/page.tsx`:

```typescript
'use client';

import { useState } from 'react';

export default function Home() {
  const [topic, setTopic] = useState('AI will replace most human jobs');
  const [optimistText, setOptimistText] = useState('');
  const [skepticText, setSkepticText] = useState('');
  const [isDebating, setIsDebating] = useState(false);
  const [status, setStatus] = useState('');

  const startDebate = async () => {
    setIsDebating(true);
    setOptimistText('');
    setSkepticText('');
    setStatus('æ­£åœ¨å–šé†’ AI å¼•æ“...');

    const startTime = Date.now();

    try {
      const response = await fetch(process.env.NEXT_PUBLIC_API_URL + '/debate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ topic, max_rounds: 3 })
      });

      const coldStartTime = Date.now() - startTime;
      if (coldStartTime > 3000) {
        setStatus('å¼•æ“å·²å°±ç·’ï¼Œé–‹å§‹è¾¯è«–ï¼');
      } else {
        setStatus('è¾¯è«–é€²è¡Œä¸­...');
      }

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();

      while (true) {
        const { done, value } = await reader!.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6));

              if (data.type === 'token') {
                if (data.node === 'optimist') {
                  setOptimistText(prev => prev + data.text);
                } else if (data.node === 'skeptic') {
                  setSkepticText(prev => prev + data.text);
                }
              }
            } catch (e) {
              console.error('Failed to parse SSE data:', e);
            }
          }
        }
      }

      setStatus('è¾¯è«–å®Œæˆï¼');
    } catch (error) {
      setStatus('éŒ¯èª¤ï¼š' + (error as Error).message);
    } finally {
      setIsDebating(false);
    }
  };

  return (
    <div className="min-h-screen p-8 bg-gradient-to-br from-blue-50 to-purple-50">
      <div className="max-w-6xl mx-auto">
        <h1 className="text-4xl font-bold mb-2 text-center">ğŸ­ DebateAI</h1>
        <p className="text-gray-600 text-center mb-8">Multi-Agent AI Debate Platform</p>

        <div className="mb-6 bg-white p-6 rounded-lg shadow-md">
          <label className="block text-sm font-medium text-gray-700 mb-2">
            è¾¯è«–ä¸»é¡Œ
          </label>
          <input
            type="text"
            value={topic}
            onChange={(e) => setTopic(e.target.value)}
            className="w-full p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent"
            placeholder="è¼¸å…¥è¾¯è«–ä¸»é¡Œ..."
            disabled={isDebating}
          />
          <button
            onClick={startDebate}
            disabled={isDebating}
            className="mt-4 w-full px-6 py-3 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:bg-gray-300 disabled:cursor-not-allowed transition-colors font-medium"
          >
            {isDebating ? status : 'é–‹å§‹è¾¯è«–'}
          </button>
        </div>

        <div className="grid grid-cols-2 gap-6">
          <div className="bg-green-50 p-6 rounded-lg shadow-md border-2 border-green-200">
            <h2 className="font-bold mb-4 text-green-800 flex items-center gap-2">
              <span className="text-2xl">ğŸ˜Š</span>
              <span>Optimist</span>
            </h2>
            <div className="prose prose-sm">
              <p className="whitespace-pre-wrap text-gray-800">
                {optimistText || 'ç­‰å¾…ç™¼è¨€...'}
              </p>
            </div>
          </div>
          <div className="bg-red-50 p-6 rounded-lg shadow-md border-2 border-red-200">
            <h2 className="font-bold mb-4 text-red-800 flex items-center gap-2">
              <span className="text-2xl">ğŸ¤”</span>
              <span>Skeptic</span>
            </h2>
            <div className="prose prose-sm">
              <p className="whitespace-pre-wrap text-gray-800">
                {skepticText || 'ç­‰å¾…ç™¼è¨€...'}
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}
```

### ç’°å¢ƒè®Šæ•¸è¨­ç½®

```bash
# backend/.env
GROQ_API_KEY=gsk_your_actual_key_here
ENVIRONMENT=development

# frontend/.env.local
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### æ¸¬è©¦

```bash
# å¾Œç«¯
cd backend
uv run uvicorn app.main:app --reload --port 8000

# å‰ç«¯
cd frontend
npm run dev
```

### é©—æ”¶æ¨™æº–

- âœ… å…©å€‹ AI agent èƒ½é‡å°ä¸»é¡Œé€²è¡Œ 3 å›åˆè¾¯è«–
- âœ… æ–‡å­—ä»¥æ‰“å­—æ©Ÿæ•ˆæœå³æ™‚é¡¯ç¤º
- âœ… å·¦å³å…©å´åˆ†åˆ¥é¡¯ç¤ºæ¨‚è§€è€…å’Œæ‡·ç–‘è€…çš„è«–è¿°
- âœ… æ¯å€‹å›æ‡‰åœ¨ 5 ç§’å…§é–‹å§‹è¼¸å‡º

---

## Phase 3: å·¥å…·èª¿ç”¨èˆ‡å®Œå–„

### ç›®æ¨™
åŠ å…¥æœå°‹å·¥å…·ï¼Œè®“ AI èƒ½æŸ¥è­‰è³‡æ–™

### å¾Œç«¯å¯¦ä½œ

#### 1. å‰µå»º `backend/app/tools.py`

```python
from langchain.tools import Tool
from tavily import TavilyClient
from duckduckgo_search import DDGS
import os

# åˆå§‹åŒ– Tavily å®¢æˆ¶ç«¯
tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY")) if os.getenv("TAVILY_API_KEY") else None

def web_search(query: str) -> str:
    """
    æœå°‹å·¥å…·ï¼šTavily (ä¸») + DuckDuckGo (å‚™æ´)

    ä¸‰å±¤å®¹éŒ¯ç­–ç•¥ï¼š
    1. å„ªå…ˆä½¿ç”¨ Tavilyï¼ˆå°ˆç‚º AI è¨­è¨ˆï¼Œæ¥µåº¦ç©©å®šï¼‰
    2. Tavily å¤±æ•—æ™‚è‡ªå‹• fallback åˆ° DuckDuckGo
    3. å…©è€…éƒ½å¤±æ•—æ™‚å„ªé›…é™ç´šï¼Œä¸æœƒå´©æ½°
    """

    # ç­–ç•¥ 1: å„ªå…ˆä½¿ç”¨ Tavily
    if tavily_client:
        try:
            response = tavily_client.search(query, max_results=3)
            if response.get("results"):
                formatted = "\n".join([
                    f"- {r['title']}: {r['content'][:150]}..."
                    for r in response["results"]
                ])
                return f"[Tavily] æœå°‹çµæœï¼š\n{formatted}"
        except Exception as tavily_error:
            print(f"Tavily failed: {tavily_error}, falling back to DuckDuckGo")

    # ç­–ç•¥ 2: Fallback åˆ° DuckDuckGo
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(query, max_results=3))
            if results:
                formatted = "\n".join([
                    f"- {r['title']}: {r['body'][:150]}..."
                    for r in results
                ])
                return f"[DuckDuckGo] æœå°‹çµæœï¼š\n{formatted}"
    except Exception as ddg_error:
        print(f"DuckDuckGo failed: {ddg_error}")

    # ç­–ç•¥ 3: å„ªé›…é™ç´š
    return (
        f"[æ³¨æ„] æœå°‹åŠŸèƒ½æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œä½†æˆ‘æœƒæ ¹æ“šå·²çŸ¥çŸ¥è­˜å›ç­”é—œæ–¼ã€Œ{query}ã€çš„å•é¡Œã€‚"
        "ï¼ˆæ­¤å›ç­”æœªç¶“å³æ™‚æ•¸æ“šé©—è­‰ï¼‰"
    )

# å‰µå»º LangChain Tool
search_tool = Tool(
    name="web_search",
    description="Search the web for current information, statistics, facts, or recent news. Use this when you need to verify claims or get up-to-date data.",
    func=web_search
)
```

#### 2. æ›´æ–° `backend/app/graph.py`

åœ¨æ–‡ä»¶é–‹é ­åŠ å…¥ï¼š

```python
from app.tools import search_tool
```

ä¿®æ”¹ LLM åˆå§‹åŒ–éƒ¨åˆ†ï¼š

```python
# ç‚º LLM ç¶å®šå·¥å…·
llm = ChatGroq(
    model="llama-3.1-70b-versatile",
    temperature=0.7,
    api_key=os.getenv("GROQ_API_KEY"),
    streaming=True
)

llm_with_tools = llm.bind_tools([search_tool])
```

ä¿®æ”¹ `optimist_node` å’Œ `skeptic_node`ï¼Œä½¿ç”¨ `llm_with_tools` ä¸¦è™•ç†å·¥å…·èª¿ç”¨ï¼š

```python
def optimist_node(state: DebateState) -> dict:
    """æ¨‚è§€è€… Agentï¼ˆæ”¯æ´å·¥å…·èª¿ç”¨ï¼‰"""
    prompt = f"""ä½ æ˜¯ä¸€ä½æ¨‚è§€çš„è¾¯æ‰‹ã€‚ä¸»é¡Œï¼š{state['topic']}

è«‹å¾ç©æ¥µçš„è§’åº¦è«–è¿°ï¼Œå¼·èª¿å„ªé»ã€æ©Ÿæœƒå’Œå¯èƒ½æ€§ã€‚ä¿æŒç°¡æ½”ï¼ˆ2-3 å¥è©±ï¼‰ã€‚

å¦‚æœéœ€è¦æœ€æ–°æ•¸æ“šæˆ–äº‹å¯¦æ”¯æŒï¼Œä½¿ç”¨ web_search å·¥å…·æŸ¥è©¢ã€‚

ä¹‹å‰çš„å°è©±ï¼š
{format_messages(state['messages'][-4:])}"""

    response = llm_with_tools.invoke(prompt)

    # è™•ç†å·¥å…·èª¿ç”¨
    if response.tool_calls:
        tool_results = []
        for tool_call in response.tool_calls:
            if tool_call["name"] == "web_search":
                result = search_tool.invoke(tool_call["args"])
                tool_results.append(result)

        # å°‡æœå°‹çµæœç´å…¥æœ€çµ‚å›æ‡‰
        final_prompt = f"{prompt}\n\næœå°‹çµæœï¼š{' '.join(tool_results)}\n\næ ¹æ“šä»¥ä¸Šè³‡è¨Šï¼Œçµ¦å‡ºä½ çš„è«–è¿°ï¼š"
        response = llm.invoke(final_prompt)

    return {
        "messages": state["messages"] + [AIMessage(content=response.content, name="optimist")],
        "current_speaker": "skeptic",
        "round_count": state["round_count"]
    }
```

å° `skeptic_node` åšé¡ä¼¼ä¿®æ”¹ã€‚

### å‰ç«¯æ›´æ–°

åœ¨å‰ç«¯åŠ å…¥æœå°‹ç‹€æ…‹æŒ‡ç¤ºï¼š

```typescript
const [isSearching, setIsSearching] = useState(false);
const [searchQuery, setSearchQuery] = useState('');

// åœ¨ SSE è™•ç†ä¸­æª¢æ¸¬å·¥å…·èª¿ç”¨
if (data.type === 'tool_call') {
  setSearchQuery(data.query);
  setIsSearching(true);
} else if (data.type === 'tool_result') {
  setIsSearching(false);
}
```

åœ¨ UI ä¸­é¡¯ç¤ºï¼š

```typescript
{isSearching && (
  <div className="mb-4 p-3 bg-yellow-50 border border-yellow-200 rounded">
    ğŸ” æ­£åœ¨æœå°‹ï¼š{searchQuery}
  </div>
)}
```

### ç’°å¢ƒè®Šæ•¸æ›´æ–°

```bash
# backend/.env
GROQ_API_KEY=gsk_your_key_here
TAVILY_API_KEY=tvly_your_key_here
ENVIRONMENT=development
```

### é©—æ”¶æ¨™æº–

- âœ… Agent å¯ä»¥è‡ªä¸»æ±ºå®šä½•æ™‚æœå°‹
- âœ… æœå°‹çµæœå½±éŸ¿è¾¯è«–å…§å®¹
- âœ… Tavily å¤±æ•—æ™‚è‡ªå‹•åˆ‡æ›åˆ° DuckDuckGo
- âœ… æœå°‹å¤±æ•—æ™‚ä¸æœƒå´©æ½°ï¼Œå„ªé›…é™ç´š

---

## é—œéµæŠ€è¡“è¦é»

### 1. SSE ä¸²æµè™•ç†

#### å¾Œç«¯è¦é»
- ä½¿ç”¨ `StreamingResponse` æ­é… async generator
- æ¯å€‹ chunk å¿…é ˆæ˜¯ `data: ...\n\n` æ ¼å¼
- è™•ç† `astream_events` çš„ä¸åŒäº‹ä»¶é¡å‹
- ä½¿ç”¨ LangGraph 0.2+ çš„æœ€æ–° API

#### å‰ç«¯è¦é»
- ä½¿ç”¨ `fetch` + `ReadableStream` è€Œé `EventSource`ï¼ˆå› ç‚ºéœ€è¦ POSTï¼‰
- æ­£ç¢ºè§£æ SSE æ ¼å¼ï¼ˆè™•ç† `data:` å‰ç¶´ï¼‰
- å¯¦ä½œé‡é€£é‚è¼¯è™•ç†ç¶²è·¯ä¸­æ–·

### 2. LangGraph ç‹€æ…‹ç®¡ç†

#### æ ¸å¿ƒæ¦‚å¿µ
- `StateGraph` å®šç¾©ç‹€æ…‹æµè½‰
- æ¯å€‹ node è¿”å› partial stateï¼ˆæœƒè‡ªå‹• mergeï¼‰
- `conditional_edges` æ ¹æ“šç‹€æ…‹æ±ºå®šä¸‹ä¸€æ­¥

#### å¸¸è¦‹éŒ¯èª¤
- âŒ å¿˜è¨˜åœ¨ node ä¸­è¿”å› `current_speaker` å°è‡´ç„¡é™å¾ªç’°
- âŒ `messages` list ä¸æ–·ç´¯ç©å°è‡´ context éé•·ï¼ˆå»ºè­°åªä¿ç•™æœ€è¿‘ 4-6 æ¢ï¼‰
- âŒ æ²’æœ‰è¨­å®š `max_rounds` å°è‡´è²»ç”¨å¤±æ§

### 3. CORS é…ç½®

#### å¿…é ˆè¨­å®š
```python
allow_origins=["http://localhost:3000", "https://*.pages.dev"]
```

#### å¸¸è¦‹å•é¡Œ
- âŒ å¿˜è¨˜åŠ å…¥å¯¦éš›çš„ Cloudflare Pages URL
- âŒ åªè¨­å®š `allow_origins=["*"]` ä½† SSE å¯èƒ½éœ€è¦ credentials
- âœ… æœ¬åœ°å’Œç”Ÿç”¢ç’°å¢ƒéƒ½è¦åŒ…å«

### 4. Groq API å„ªåŒ–

#### é€Ÿåº¦å„ªåŒ–
- ä½¿ç”¨ `llama-3.1-70b-versatile` æˆ– `llama-3.1-8b-instant`
- è¨­å®šåˆç†çš„ `max_tokens`ï¼ˆé¿å…éé•·å›æ‡‰ï¼‰
- ä½¿ç”¨ `temperature=0.7`ï¼ˆå¹³è¡¡å‰µæ„å’Œä¸€è‡´æ€§ï¼‰

#### æˆæœ¬æ§åˆ¶
- æ¯æ¬¡è¾¯è«–ç´„ä½¿ç”¨ 1500-2000 tokens
- Groq å…è²»é¡åº¦é€šå¸¸è¶³å¤ é–‹ç™¼æ¸¬è©¦
- è¨­å®š rate limitingï¼ˆé¿å…è¢«æ¿«ç”¨ï¼‰

---

## é¢¨éšªç·©è§£ç­–ç•¥

### 1. API é™æµé¢¨éšª

**é¢¨éšªï¼š** Groq æˆ– Tavily API é”åˆ°é™é¡

**ç·©è§£æªæ–½ï¼š**
- å¯¦ä½œå¾Œç«¯ rate limiting
- æº–å‚™å¤šå€‹ API key è¼ªæ›¿
- åŠ å…¥ä½¿ç”¨é‡ç›£æ§ï¼ˆå¯ç”¨ Redis è¨ˆæ•¸å™¨ï¼‰

### 2. Cloud Run å†·å•Ÿå‹•

**é¢¨éšªï¼š** 15 åˆ†é˜ç„¡è«‹æ±‚å¾Œä¼‘çœ ï¼Œé¦–æ¬¡è«‹æ±‚æ…¢

**ç·©è§£æªæ–½ï¼š**

#### æ–¹æ¡ˆ A: å‰ç«¯ UX å„ªåŒ–ï¼ˆé›¶æˆæœ¬ï¼‰
```typescript
setStatus('æ­£åœ¨å–šé†’ AI å¼•æ“...');
const startTime = Date.now();
const response = await fetch(...);
const coldStartTime = Date.now() - startTime;

if (coldStartTime > 3000) {
  setStatus('å¼•æ“å·²å°±ç·’ï¼Œé–‹å§‹è¾¯è«–ï¼');
}
```

#### æ–¹æ¡ˆ B: Keep-Alive è…³æœ¬ï¼ˆDemo ä½¿ç”¨ï¼‰
```bash
#!/bin/bash
# keep-alive.sh
API_URL="https://your-api.a.run.app/health"

while true; do
  echo "$(date): Pinging $API_URL"
  curl -s $API_URL > /dev/null
  sleep 300  # æ¯ 5 åˆ†é˜ ping ä¸€æ¬¡
done
```

ä½¿ç”¨æ–¹å¼ï¼š
```bash
# Demo å‰ 30 åˆ†é˜åŸ·è¡Œ
./keep-alive.sh &

# è¨˜ä¸‹ PID
echo $! > keep-alive.pid

# Demo çµæŸå¾Œåœæ­¢
kill $(cat keep-alive.pid)
```

#### æ–¹æ¡ˆ C: æœ€å°å¯¦ä¾‹ = 1ï¼ˆç´„ $5-10/æœˆï¼‰
åƒ…åœ¨é‡è¦å±•ç¤ºæœŸé–“å•Ÿç”¨ï¼š
```bash
gcloud run services update debate-api --min-instances 1
```

### 3. SSE é€£æ¥ç©©å®šæ€§

**é¢¨éšªï¼š** ç¶²è·¯ä¸­æ–·æˆ–é•·æ™‚é–“ç„¡æ•¸æ“šå°è‡´é€£æ¥æ–·é–‹

**ç·©è§£æªæ–½ï¼š**
- å‰ç«¯å¯¦ä½œè‡ªå‹•é‡é€£æ©Ÿåˆ¶
- å¾Œç«¯åŠ å…¥ keepalive pingï¼ˆæ¯ 30 ç§’ç™¼é€ç©ºæ•¸æ“šï¼‰
- è¨­å®šåˆç†çš„ timeoutï¼ˆå»ºè­° 300 ç§’ï¼‰

### 4. æœå°‹å·¥å…·ä¸ç©©å®š

**é¢¨éšªï¼š** DuckDuckGo è¢«å°é–æˆ–é™æµ

**ç·©è§£æªæ–½ï¼š**
- âœ… å·²å¯¦æ–½ï¼šä¸‰å±¤å®¹éŒ¯ç­–ç•¥ï¼ˆTavily â†’ DuckDuckGo â†’ å„ªé›…é™ç´šï¼‰
- Demo æ°¸é ä¸æœƒå› ç‚ºæœå°‹å¤±æ•—è€Œå´©æ½°

---

## é›¶æˆæœ¬ç­–ç•¥æ¸…å–®

ç‚ºç¢ºä¿æˆæœ¬ç‚º $0ï¼Œåš´æ ¼éµå®ˆä»¥ä¸‹è¨­å®šï¼š

### Google Cloud Run
- âœ… ä½¿ç”¨å…è²»é¡åº¦ï¼ˆ200 è¬æ¬¡è«‹æ±‚/æœˆï¼‰
- âœ… æœ€å°å¯¦ä¾‹æ•¸è¨­ç‚º 0ï¼ˆæ¥å—å†·å•Ÿå‹•ï¼‰
- âœ… å…§å­˜é™åˆ¶ 512MBï¼ˆå¤ ç”¨ä¸”åœ¨å…è²»ç¯„åœï¼‰
- âœ… CPU é™åˆ¶ 1 vCPU
- âœ… Timeout è¨­ç‚º 300 ç§’
- âŒ ä¸ä½¿ç”¨ Cloud SQLã€Cloud Storage ç­‰ä»˜è²»æœå‹™

### Cloudflare Pages
- âœ… å®Œå…¨å…è²»ï¼ˆç„¡é™è«‹æ±‚ï¼‰
- âœ… è‡ªå‹• HTTPS
- âœ… å…¨çƒ CDN

### API Services
- âœ… Groq: ä½¿ç”¨å…è²»é¡åº¦ï¼Œè¨­å®š rate limiting
- âœ… Tavily: 1000 æ¬¡/æœˆå…è²»
- âœ… DuckDuckGo: å®Œå…¨å…è²»

### é¿å…ä½¿ç”¨çš„ä»˜è²»æœå‹™
- âŒ Cloud SQL / Firebase
- âŒ Cloud Storage
- âŒ Cloud Loggingï¼ˆä½¿ç”¨ stdout å³å¯ï¼‰
- âŒ Cloud Run æœ€å°å¯¦ä¾‹ â‰¥ 1ï¼ˆæœƒç”¢ç”Ÿæˆæœ¬ï¼Œé™¤é Demo ç•¶å¤©ï¼‰

---

## å¾ŒçºŒæ“´å±•åŠŸèƒ½ï¼ˆWeek 4ï¼‰

æ ¹æ“šæ¸¬è©¦çµæœï¼Œå¯é¸æ“‡æ€§åŠ å…¥ï¼š

1. **ä¸»é¡Œæ¨¡æ¿åº«**: é è¨­ 10 å€‹ç†±é–€è¾¯è«–ä¸»é¡Œ
2. **å°è©±æ­·å²**: ä½¿ç”¨ localStorage å„²å­˜éå¾€è¾¯è«–
3. **Moderator ç¸½çµ**: ç¬¬ä¸‰å€‹ agent ç”Ÿæˆè¾¯è«–ç¸½çµ
4. **åˆ†äº«åŠŸèƒ½**: ç”Ÿæˆå¯åˆ†äº«çš„è¾¯è«–è¨˜éŒ„é€£çµ
5. **å¤šèªè¨€æ”¯æŒ**: åˆ‡æ›ä¸­è‹±æ–‡ä»‹é¢
6. **æ·±è‰²æ¨¡å¼**: UI ä¸»é¡Œåˆ‡æ›
7. **å›åˆé€²åº¦æ¢**: é¡¯ç¤ºç•¶å‰è¾¯è«–é€²åº¦
8. **Export åŠŸèƒ½**: å°å‡ºè¾¯è«–è¨˜éŒ„ç‚º Markdown æˆ– PDF

---

## å¸¸è¦‹å•é¡Œ (FAQ)

### Q: ç‚ºä»€éº¼é¸æ“‡ uv è€Œä¸æ˜¯ pip?
A: uv æ¯” pip å¿« 10-100 å€ï¼Œå…§å»ºä¾è³´é–å®šï¼Œæ˜¯ Python å·¥å…·éˆçš„æœªä¾†è¶¨å‹¢ã€‚

### Q: Tavily å’Œ DuckDuckGo å“ªå€‹æ›´å¥½ï¼Ÿ
A: Tavily æ›´ç©©å®šä½†æœ‰æ¬¡æ•¸é™åˆ¶ï¼ˆ1000 æ¬¡/æœˆï¼‰ï¼ŒDuckDuckGo å…è²»ä½†ä¸ç©©å®šã€‚æˆ‘å€‘æ¡ç”¨ Tavily å„ªå…ˆ + DuckDuckGo å‚™æ´çš„ç­–ç•¥ã€‚

### Q: å¦‚ä½•é¿å… Groq API è¶…é¡ï¼Ÿ
A: åœ¨å¾Œç«¯å¯¦ä½œ rate limitingï¼Œç›£æ§ä½¿ç”¨é‡ï¼Œå¿…è¦æ™‚æº–å‚™å¤šå€‹ API key è¼ªæ›¿ã€‚

### Q: Cloud Run å†·å•Ÿå‹•å¤ªæ…¢æ€éº¼è¾¦ï¼Ÿ
A: Demo å‰ä½¿ç”¨ keep-alive è…³æœ¬ä¿æŒæº«ç†±ï¼Œæˆ–åœ¨å‰ç«¯é¡¯ç¤ºã€Œæ­£åœ¨å–šé†’å¼•æ“ã€çš„å‹å¥½æç¤ºã€‚

### Q: å¦‚ä½•è™•ç† CORS éŒ¯èª¤ï¼Ÿ
A: ç¢ºä¿ FastAPI çš„ `allow_origins` åŒ…å«å‰ç«¯çš„å¯¦éš› URLï¼ˆæœ¬åœ°å’Œç”Ÿç”¢ç’°å¢ƒï¼‰ã€‚

---

## æˆåŠŸæŒ‡æ¨™

### Phase 1 å®Œæˆæ¨™æº–
- âœ… å¯ä»¥å¾ç€è¦½å™¨çœ‹åˆ° "Hello World" ä¸²æµ
- âœ… CORS é…ç½®æ­£ç¢º
- âœ… å‰å¾Œç«¯å¯åœ¨ localhost å’Œé›²ç«¯ç’°å¢ƒé‹è¡Œ

### Phase 2 å®Œæˆæ¨™æº–
- âœ… å…©å€‹ AI agent å¯ä»¥å°±ä¸»é¡Œé€²è¡Œ 3 å›åˆè¾¯è«–
- âœ… å°è©±ä»¥æ‰“å­—æ©Ÿæ•ˆæœå³æ™‚é¡¯ç¤º
- âœ… ç„¡æ˜é¡¯å¡é “ï¼ˆæ¯å€‹å›æ‡‰ < 5 ç§’é–‹å§‹è¼¸å‡ºï¼‰

### Phase 3 å®Œæˆæ¨™æº–
- âœ… Agent å¯ä»¥è‡ªä¸»æ±ºå®šä½•æ™‚æœå°‹
- âœ… æœå°‹çµæœå½±éŸ¿è¾¯è«–å…§å®¹
- âœ… æœå°‹å¤±æ•—æ™‚å„ªé›…é™ç´š
- âœ… Moderator å¯ä»¥ç”Ÿæˆæœ‰æ„ç¾©çš„ç¸½çµ

---

## çµè«–

é€™æ˜¯ä¸€å€‹**é«˜åº¦å¯è¡Œ**çš„å°ˆæ¡ˆï¼ˆ9/10ï¼‰ï¼ŒæŠ€è¡“é¸å‹åˆç†ï¼Œæ¶æ§‹è¨­è¨ˆæ¸…æ™°ã€‚

**é—œéµæˆåŠŸå› ç´ :**
1. âœ… ä½¿ç”¨ç¾ä»£åŒ–å·¥å…·éˆï¼ˆuvï¼‰
2. âœ… æ¡ç”¨æœ€æ–° LangGraph 0.2+ API
3. âœ… ä¸‰å±¤å®¹éŒ¯çš„æœå°‹ç­–ç•¥
4. âœ… å†·å•Ÿå‹• UX å„ªåŒ–
5. âœ… åš´æ ¼éµå®ˆé›¶æˆæœ¬ç­–ç•¥
6. âœ… æ¼¸é€²å¼é–‹ç™¼ï¼ˆæ¯å€‹ Phase éƒ½æœ‰å¯å±•ç¤ºæˆæœï¼‰

**å°ˆæ¡ˆå®Œæˆå¾Œä½ å°‡ç²å¾—:**
- å®Œæ•´çš„ Multi-Agent AI æ‡‰ç”¨ä½œå“
- FastAPI + LangGraph + Next.js å¯¦æˆ°ç¶“é©—
- SSE ä¸²æµæŠ€è¡“æŒæ¡
- é›²ç«¯éƒ¨ç½²ï¼ˆGCP + Cloudflareï¼‰ç¶“é©—
- ç¾ä»£åŒ– Python å·¥å…·éˆï¼ˆuvï¼‰ä½¿ç”¨ç¶“é©—
- ä¸€å€‹å¯æ”¾å…¥ä½œå“é›†çš„å®Œæ•´å°ˆæ¡ˆ

**æº–å‚™å¥½é–‹å§‹äº†å—ï¼Ÿ** å¾ Phase 0 é–‹å§‹ï¼Œå…ˆå»ºç«‹å°ˆæ¡ˆçµæ§‹ï¼

---

## åƒè€ƒè³‡æ–™

- [LangGraph å®˜æ–¹æ–‡æª”](https://langchain-ai.github.io/langgraph/)
- [uv å®˜æ–¹æ–‡æª”](https://docs.astral.sh/uv/)
- [FastAPI å®˜æ–¹æ–‡æª”](https://fastapi.tiangolo.com/)
- [Groq API æ–‡æª”](https://console.groq.com/docs)
- [Tavily API æ–‡æª”](https://docs.tavily.com/)
- [Google Cloud Run æ–‡æª”](https://cloud.google.com/run/docs)
- [Cloudflare Pages æ–‡æª”](https://developers.cloudflare.com/pages/)
